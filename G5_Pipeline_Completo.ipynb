{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "G5_Pipeline_Completo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LucasBrandaoGomes/Projeto-ETL-Consultas-SQL/blob/main/G5_Pipeline_Completo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZQy515Wq1Q7"
      },
      "source": [
        "pip install apache-beam[interactive]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUsq5rBOw8Qs"
      },
      "source": [
        "pip install apache-beam[gcp]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eu4wCmTFxHSu"
      },
      "source": [
        "pip install google-cloud-pubsub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STcfeNZ0zmm5"
      },
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "def download_blob(bucket_name, source_blob_name, destination_file_name):\n",
        "    storage_client = storage.Client()\n",
        "    bucket = storage_client.bucket(bucket_name)\n",
        "    blob = bucket.blob(source_blob_name)\n",
        "    blob.download_to_filename(destination_file_name)\n",
        "\n",
        "    print(\n",
        "        \"Downloaded storage object {} from bucket {} to local file {}.\".format(\n",
        "            source_blob_name, bucket_name, destination_file_name\n",
        "        )\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHg-Shb_zz7M",
        "outputId": "2ad11b0e-b061-4bed-9c66-cdc8a79c6cc8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZVpt1BpcbTZ"
      },
      "source": [
        "import os\n",
        "from google.cloud import storage\n",
        "\n",
        "serviceAccount = '/content/chave_projetofinal-grupo5-d2c4a9d78233.json'\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = serviceAccount"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAfJLZA4z-Oi",
        "outputId": "d94f4a79-69de-4bdb-f710-927092c8e395"
      },
      "source": [
        "download_blob(\"projeto-final-bucket-g5\", \\\n",
        "              \"saida/df_cobertura_florestal_pipeline.csv\", \\\n",
        "              \"/content/drive/MyDrive/dados_soulcode/pipeline/df_cobertura_florestal_pipeline.csv\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded storage object saida/df_cobertura_florestal_pipeline.csv from bucket projeto-final-bucket-g5 to local file /content/drive/MyDrive/dados_soulcode/pipeline/df_cobertura_florestal_pipeline.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2isXjx5xNlJ"
      },
      "source": [
        "# Primeira etapa - upload dos arquivo baixados no drive para o tópico \"topicov1\",\n",
        "# criado no Pub/Sub, com assinatura \"assinaturatp1\" vinculada, para publicação \n",
        "# dos dados recebidos.\n",
        "\n",
        "import csv        #importação do módulo módulo csv, perimitindo uso de classes \n",
        "                  # para ler e gravar dados no formato .csv\n",
        "\n",
        "import time       #importação do módulo time, para utilização da função time.sleep,\n",
        "                  # a fim de proporcionar melhor visualização entre \n",
        "                  # uma mensagem e a próxima\n",
        "\n",
        "from google.cloud import pubsub_v1  #importação do módulo pubsub_v1 da biblioteca\n",
        "                                    # google.cloud, para que utilizemos \n",
        "                                    # as funcionalidades do Pub/Sub \n",
        "                                    # no ambiente do Google Colaboratory\n",
        "\n",
        "import os  \n",
        "\n",
        "service_account_key = r\"/content/chave_projetofinal-grupo5-d2c4a9d78233.json\"\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = service_account_key\n",
        "\n",
        "topico = 'projects/projetofinal-grupo5/topics/topicov1'  #definição do caminho para  \n",
        "                                                         #publicação da leitura \n",
        "                                                         # do arquivo dentro do Pub/Sub\n",
        "\n",
        "publisher = pubsub_v1.PublisherClient()                  # uso de função  de publicação\n",
        "                                                         # a ser utilizada do módulo  Pub/Sub \n",
        "\n",
        "entrada = r\"/content/drive/MyDrive/dados_soulcode/pipeline/df_cobertura_florestal_pipeline.csv\" \n",
        "\n",
        "                                                         #definição do caminho do arquivo a ser\n",
        "                                                         #enviado ao tópico Pub/Sub já definido    \n",
        "\n",
        "with open(entrada, 'rb') as file:                        #definição de função que mostra a evolução\n",
        "                                                         # da leitura do arquivo e subsequente publicação\n",
        "                                                         # e publicação das mensagens no tópico \n",
        "    for row in file:\n",
        "        print('Publicando dados no tópico')\n",
        "        publisher.publish(topico,row)\n",
        "        time.sleep(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tf6dAfEd2U6R"
      },
      "source": [
        "import apache_beam as beam\n",
        "import os\n",
        "from apache_beam.options.pipeline_options import PipelineOptions #importação da função\n",
        "                                                                 #PipelineOptions para\n",
        "                                                                 #definição dos parâmetros\n",
        "                                                                 #para ordenação da \n",
        "                                                                 #montagem do nosso template\n",
        "from apache_beam import window   #importação de função window, para definição de janelas de\n",
        "                                 #tempo realtivas a recorete/captura de dados, \n",
        "                                 #essencial quandose trabalha com pipelines de dados em streaming\n",
        "\n",
        "pipeline_options = {\n",
        "    'project': 'projetofinal-grupo5',   #ID do Projeto\n",
        "    'runner': 'DataflowRunner',         #executor do Projeto\n",
        "    'region': 'southamerica-east1',     #região onde o projeto será executado\n",
        "    'staging_location': 'gs://projeto-final-bucket-g5/temp', \n",
        "                         #staging é a área de preparação/\n",
        "                         #espaço de armazenamento necessário p/ execução do trabalho \n",
        "    'temp_location': 'gs://projeto-final-bucket-g5/temp', #local de processamento temporário, \n",
        "                                                          # arquivos apagadosdepois\n",
        "    'template_location': 'gs://projeto-final-bucket-g5/template/projeto_final_g5_TEMPLATE',\n",
        "                         #local onde o template será armazenado\n",
        "    'save_main_session': True, #declaração para que sessão seja salva\n",
        "    'streaming': True #declaração de que se trata de uma pipeline de streaming}\n",
        "\n",
        "\n",
        "pipeline_options = PipelineOptions.from_dictionary(pipeline_options)\n",
        "p1 = beam.Pipeline(options=pipeline_options)\n",
        "\n",
        "serviceAccount = '/content/chave_projetofinal-grupo5-d2c4a9d78233.json'\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = serviceAccount\n",
        "\n",
        "subscription = 'projects/projetofinal-grupo5/subscriptions/assinaturatp1'  \n",
        "  #definição do local de onde serão buscados os arquivos para inserção na pipeline, \n",
        "  #quando o template dela for utlizado no Dataflow\n",
        "\n",
        "saida = 'projects/projetofinal-grupo5/topics/topicov2'\n",
        "  #definição de local onde os arquivos tratados pelos processos da Pipeline serão\n",
        "  #publicados após o tratamento\n",
        "\n",
        "class separar_linhas(beam.DoFn):\n",
        "  def process(self,record):\n",
        "    return [record.decode(\"utf-8\").split(',')]\n",
        "\n",
        "pcollection_entrada = (\n",
        "    p1  | 'Read from pubsub topic' >> beam.io.ReadFromPubSub(subscription= subscription)\n",
        ")\n",
        " #definição do arquivo a ser lido na pipeline construída\n",
        "\n",
        "Paises_Asia = (\n",
        "    pcollection_entrada\n",
        "    | \"Separar por Vírgulas Países\" >> beam.ParDo(separar_linhas())\n",
        "     #uso da função separadora de linhas \n",
        "    | \"Continente Ásia1\" >> beam.Filter(lambda record: record[0] == 'Ásia')\n",
        "     #recorte, dentro do dataset, por Continente\n",
        "    | \"Paises Ásia1\" >> beam.Filter(lambda record: record[1])\n",
        "     #recorte, dentro do dataset, dos Países específicos dentro do Continente\n",
        "    | \"Agregação de colunas1\" >> beam.Map(lambda record : (record[0], record[1]))\n",
        "     #agregação das colunas Continente e País\n",
        "    | \"Window1\" >> beam.WindowInto(window.SlidingWindows(10,5))\n",
        "     #definição de parâmetros da janela  \n",
        "    | \"Combinar os dados1\" >> beam.GroupByKey()\n",
        "     #definição da forma de combinar os dados para posterior manipulação  \n",
        ")\n",
        "\n",
        "Variacao_Area_Florestal_1990_2010 = (\n",
        "    pcollection_entrada\n",
        "    | \"Separar por Vírgulas Area Florestal\" >> beam.ParDo(separar_linhas())\n",
        "     #uso da função separadora de linhas \n",
        "    | \"Continente Ásia2\" >> beam.Filter(lambda record: record[0] == 'Ásia')\n",
        "     #recorte, dentro do dataset, por Continente\n",
        "    | \"Variacao_Area_Florestal_1990_2010\" >> beam.Filter(lambda record: float(record[9]))\n",
        "     #recorte, dentro do dataset, da Variaçao de Área Florestal \n",
        "     # dentro de um período de tempo, dentro do Continente\n",
        "    | \"Agregação de colunas2\" >> beam.Map(lambda record : (record[0], float(record[9])))\n",
        "     #agregação das colunas Continente e Variaçao de Área Florestal 1990-2010 \n",
        "    | \"Window2\" >> beam.WindowInto(window.SlidingWindows(10,5))\n",
        "     #definição de parâmetros da janela  \n",
        "    | \"Combinar os dados2\" >> beam.GroupByKey()   \n",
        "     #definição da forma de combinar os dados para posterior manipulação   \n",
        ")\n",
        "\n",
        "Tabela_Asia_Var_CFlorestal_90_10 = (   \n",
        "    {'Paises_Asia' : Paises_Asia, 'Variacao_Area_Florestal_1990_2010': Variacao_Area_Florestal_1990_2010}  \n",
        "                                          #junção dos dadoo tratados nas outra etapa em uma Tabela Final\n",
        "    | \"join Paises_Asia, Variacao_Area_Florestal_1990_2010\" >> beam.CoGroupByKey() \n",
        "                                          #definição de função pra junção\n",
        "    | 'Converting to byte String' >> beam.Map(lambda row: (''.join(str(row)).encode('utf-8')) )\n",
        "                                          #definição do formato de leitura do aquivo final\n",
        "    | \"Escrever no Tópico\" >> beam.io.WriteToPubSub(saida)\n",
        "                                          #definição do local de armazenamento da Tabela Final\n",
        ")\n",
        "\n",
        "result = p1.run()\n",
        "result.wait_until_finish()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}